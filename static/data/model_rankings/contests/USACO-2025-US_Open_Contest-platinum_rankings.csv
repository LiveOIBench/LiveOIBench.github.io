Model,Total Score,Included Tasks,Solved Tasks,Partial Tasks,Pass Rate (%),Relative Score (%),Medal,Platinum Score,Rank,Competition,Year,Round,Contest_Key
gpt-o3-mini-high,95.0,3,0,1,0.0,9.50950950950951,None,95.0,1,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-32B,95.0,3,0,1,0.0,9.50950950950951,None,95.0,2,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
gemini-2.5-pro,95.0,3,0,1,0.0,9.50950950950951,None,95.0,3,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-14B,95.0,3,0,1,0.0,9.50950950950951,None,95.0,4,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-30B,95.0,3,0,1,0.0,9.50950950950951,None,95.0,5,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-8B,95.0,3,0,1,0.0,9.50950950950951,None,95.0,6,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
QwQ-32B,95.0,3,0,1,0.0,9.50950950950951,None,95.0,7,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
deepseek-reasoner,95.0,3,0,1,0.0,9.50950950950951,None,95.0,8,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
DeepSeek-R1-Distill-Llama-70B,24.0,3,0,1,0.0,2.4024024024024024,None,24.0,9,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
gpt-4.1,24.0,3,0,1,0.0,2.4024024024024024,None,24.0,10,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen2.5-Coder-7B-Instruct,0.0,3,0,0,0.0,0.0,None,0.0,11,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Codestral-22B-v0.1,0.0,3,0,0,0.0,0.0,None,0.0,12,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-30B-Non-Thinking,0.0,3,0,0,0.0,0.0,None,0.0,13,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
DeepSeek-Coder-V2-Lite-Instruct,0.0,3,0,0,0.0,0.0,None,0.0,14,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-4B-Non-Thinking,0.0,3,0,0,0.0,0.0,None,0.0,15,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Llama-3.1-8B-Instruct,0.0,3,0,0,0.0,0.0,None,0.0,16,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Mistral-Small-3.1-24B-2503,0.0,3,0,0,0.0,0.0,None,0.0,17,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen2.5-Coder-32B-Instruct,0.0,3,0,0,0.0,0.0,None,0.0,18,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen2.5-72B,0.0,3,0,0,0.0,0.0,None,0.0,19,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-32B-Non-Thinking,0.0,3,0,0,0.0,0.0,None,0.0,20,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-8B-Non-Thinking,0.0,3,0,0,0.0,0.0,None,0.0,21,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen2.5-Coder-14B-Instruct,0.0,3,0,0,0.0,0.0,None,0.0,22,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Mistral-Large-Instruct-2411,0.0,3,0,0,0.0,0.0,None,0.0,23,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-14B-Non-Thinking,0.0,3,0,0,0.0,0.0,None,0.0,24,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Llama-3.3-70B-Instruct,0.0,3,0,0,0.0,0.0,None,0.0,25,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
deepseek-chat,0.0,3,0,0,0.0,0.0,None,0.0,26,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
DeepSeek-R1-Distill-Qwen-14B,0.0,3,0,0,0.0,0.0,None,0.0,27,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
Qwen3-4B,0.0,3,0,0,0.0,0.0,None,0.0,28,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
DeepSeek-R1-Distill-Qwen-32B,0.0,3,0,0,0.0,0.0,None,0.0,29,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
gemini-2.5-flash,0.0,3,0,0,0.0,0.0,None,0.0,30,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
DeepSeek-R1-Distill-Llama-8B,0.0,3,0,0,0.0,0.0,None,0.0,31,USACO,2025,platinum,USACO-2025-US_Open_Contest-platinum
