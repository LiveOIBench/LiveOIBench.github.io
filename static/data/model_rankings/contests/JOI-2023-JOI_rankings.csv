Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gpt-oss-120b-high,311.0,5,311.0,78.2,60.0,Bronze,107,64.90066225165563,1,62.2
gpt-5,311.0,5,311.0,77.69,60.0,Bronze,107,64.90066225165563,2,62.2
deepseek-reasoner,289.0,5,289.0,67.77,40.0,Bronze,142,53.311258278145694,3,57.8
gemini-2.5-pro,254.0,5,254.0,77.51,40.0,Bronze,150,50.66225165562914,4,50.8
gpt-o3-mini-high,234.0,5,234.0,67.09,40.0,None,165,45.6953642384106,5,46.8
gemini-2.5-flash,217.0,5,217.0,63.18,40.0,None,174,42.71523178807947,6,43.4
gpt-oss-20b-medium,211.0,5,211.0,57.69,40.0,None,174,42.71523178807947,7,42.2
gpt-oss-20b-high,211.0,5,211.0,57.69,40.0,None,174,42.71523178807947,8,42.2
gpt-oss-120b-medium,208.0,5,208.0,50.07,40.0,None,176,42.05298013245033,9,41.6
seed-oss_8192,208.0,5,208.0,48.82,40.0,None,176,42.05298013245033,10,41.6
seed-oss_-1,203.0,5,203.0,62.14,40.0,None,179,41.05960264900662,11,40.6
seed-oss_16384,200.0,5,200.0,58.68,40.0,None,179,41.05960264900662,12,40.0
Qwen3-30B,190.0,5,190.0,63.98,20.0,None,219,27.814569536423843,13,38.0
Qwen3-8B,163.0,5,163.0,48.25,20.0,None,231,23.841059602649008,14,32.6
Qwen3-32B,155.0,5,155.0,61.25,20.0,None,233,23.178807947019866,15,31.0
DeepSeek-R1-Distill-Llama-70B,130.0,5,130.0,51.23,20.0,None,237,21.85430463576159,16,26.0
QwQ-32B,111.0,5,111.0,47.19,20.0,None,241,20.52980132450331,17,22.2
gpt-oss-20b-low,111.0,5,111.0,43.08,20.0,None,241,20.52980132450331,18,22.2
gpt-oss-120b-low,108.0,5,108.0,41.1,20.0,None,245,19.205298013245034,19,21.6
DeepSeek-R1-Distill-Qwen-32B,103.0,5,103.0,39.07,20.0,None,245,19.205298013245034,20,20.6
Qwen3-4B,100.0,5,100.0,29.39,20.0,None,245,19.205298013245034,21,20.0
DeepSeek-R1-Distill-Qwen-14B,100.0,5,100.0,29.39,20.0,None,245,19.205298013245034,22,20.0
Llama-3.3-70B-Instruct,36.0,5,36.0,39.42,0.0,None,292,3.642384105960265,23,7.2
deepseek-chat,30.0,5,30.0,44.5,0.0,None,295,2.6490066225165565,24,6.0
gpt-4.1,21.0,5,21.0,32.04,0.0,None,300,0.9933774834437086,25,4.2
Mistral-Large-Instruct-2411,13.0,5,13.0,24.57,0.0,None,301,0.6622516556291391,26,2.6
Qwen2.5-72B,13.0,5,13.0,23.42,0.0,None,301,0.6622516556291391,27,2.6
Qwen2.5-Coder-14B-Instruct,13.0,5,13.0,23.42,0.0,None,301,0.6622516556291391,28,2.6
Qwen3-30B-Non-Thinking,13.0,5,13.0,30.2,0.0,None,301,0.6622516556291391,29,2.6
seed-oss_1024,10.0,5,10.0,14.73,0.0,None,302,0.33112582781456956,30,2.0
seed-oss_512,10.0,5,10.0,14.73,0.0,None,302,0.33112582781456956,31,2.0
Qwen2.5-Coder-32B-Instruct,10.0,5,10.0,22.1,0.0,None,302,0.33112582781456956,32,2.0
Qwen2.5-Coder-7B-Instruct,10.0,5,10.0,17.89,0.0,None,302,0.33112582781456956,33,2.0
Codestral-22B-v0.1,3.0,5,3.0,19.93,0.0,None,302,0.33112582781456956,34,0.6
Qwen3-4B-Non-Thinking,3.0,5,3.0,16.34,0.0,None,302,0.33112582781456956,35,0.6
Qwen3-14B,0.0,5,0.0,0.0,0.0,None,303,0.0,36,0.0
Qwen3-32B-Non-Thinking,0.0,5,0.0,0.0,0.0,None,303,0.0,37,0.0
Qwen3-8B-Non-Thinking,0.0,5,0.0,0.0,0.0,None,303,0.0,38,0.0
DeepSeek-R1-Distill-Qwen-7B,0.0,5,0.0,0.0,0.0,None,303,0.0,39,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,5,0.0,6.42,0.0,None,303,0.0,40,0.0
Llama-4-Scout,0.0,5,0.0,7.87,0.0,None,303,0.0,41,0.0
seed-oss_2048,0.0,5,0.0,11.07,0.0,None,303,0.0,42,0.0
seed-oss_4096,0.0,5,0.0,8.44,0.0,None,303,0.0,43,0.0
Llama-3.1-8B-Instruct,0.0,5,0.0,10.1,0.0,None,303,0.0,44,0.0
DeepSeek-Coder-V2-Lite-Instruct,0.0,5,0.0,20.57,0.0,None,303,0.0,45,0.0
Qwen3-14B-Non-Thinking,0.0,5,0.0,7.87,0.0,None,303,0.0,46,0.0
Mistral-Small-3.1-24B-2503,0.0,5,0.0,10.24,0.0,None,303,0.0,47,0.0
seed-oss_0,0.0,5,0.0,9.39,0.0,None,303,0.0,48,0.0
