Model,Total Score,Included Tasks,Solved Tasks,Partial Tasks,Pass Rate (%),Relative Score (%),Medal,Bronze Score,Silver Score,Gold Score,Rank,Competition,Year,Round,Contest_Key
gpt-5,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,1,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-oss-20b-high,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,2,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-oss-120b-high,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,3,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-oss-120b-medium,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,4,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gemini-2.5-pro,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,5,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-o3-mini-high,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,6,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-oss-20b-medium,2084.0,9,6,1,66.66666666666666,69.5362028695362,Silver,667.0,1000.0,417.0,7,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-oss-120b-low,2001.0,9,6,0,66.66666666666666,66.76676676676678,Silver,667.0,1000.0,334.0,8,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_-1,1799.0,9,5,2,55.55555555555556,60.0266933600267,Silver,667.0,1000.0,132.0,9,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_16384,1751.0,9,5,1,55.55555555555556,58.4250917584251,Silver,667.0,1000.0,84.0,10,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gemini-2.5-flash,1735.0,9,5,1,55.55555555555556,57.89122455789123,None,667.0,734.0,334.0,11,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-oss-20b-low,1668.0,9,5,0,55.55555555555556,55.65565565565566,Silver,667.0,1000.0,1.0,12,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_8192,1252.0,9,3,2,33.33333333333333,41.77510844177511,None,501.0,667.0,84.0,13,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-32B,1169.0,9,3,1,33.33333333333333,39.00567233900567,None,501.0,667.0,1.0,14,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
deepseek-reasoner,973.0,9,2,2,22.22222222222222,32.4657991324658,None,305.0,667.0,1.0,15,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
gpt-4.1,954.0,9,2,2,22.22222222222222,31.83183183183183,None,286.0,667.0,1.0,16,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
QwQ-32B,886.0,9,1,3,11.11111111111111,29.562896229562895,None,305.0,580.0,1.0,17,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-14B,886.0,9,1,3,11.11111111111111,29.562896229562895,None,305.0,580.0,1.0,18,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-30B,867.0,9,1,3,11.11111111111111,28.928928928928926,None,286.0,580.0,1.0,19,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_4096,717.0,9,1,2,11.11111111111111,23.923923923923923,None,119.0,597.0,1.0,20,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
DeepSeek-R1-Distill-Llama-70B,634.0,9,0,4,0.0,21.15448782115449,None,286.0,347.0,1.0,21,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-4B,567.0,9,0,4,0.0,18.91891891891892,None,286.0,280.0,1.0,22,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-8B,567.0,9,0,4,0.0,18.91891891891892,None,286.0,280.0,1.0,23,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
DeepSeek-R1-Distill-Qwen-32B,519.0,9,0,3,0.0,17.31731731731732,None,138.0,380.0,1.0,24,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-30B-Non-Thinking,511.0,9,0,4,0.0,17.050383717050384,None,286.0,224.0,1.0,25,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
deepseek-chat,432.0,9,0,3,0.0,14.414414414414415,None,119.0,312.0,1.0,26,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Mistral-Large-Instruct-2411,388.0,9,0,3,0.0,12.94627961294628,None,286.0,101.0,1.0,27,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
DeepSeek-R1-Distill-Qwen-14B,367.0,9,0,2,0.0,12.245578912245579,None,119.0,247.0,1.0,28,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen2.5-Coder-14B-Instruct,330.0,9,0,3,0.0,11.01101101101101,None,258.0,71.0,1.0,29,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Llama-3.3-70B-Instruct,288.0,9,0,2,0.0,9.60960960960961,None,286.0,1.0,1.0,30,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Llama-4-Scout,288.0,9,0,2,0.0,9.60960960960961,None,286.0,1.0,1.0,31,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen2.5-72B,279.0,9,0,3,0.0,9.30930930930931,None,207.0,71.0,1.0,32,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-8B-Non-Thinking,268.0,9,0,2,0.0,8.942275608942275,None,266.0,1.0,1.0,33,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Mistral-Small-3.1-24B-2503,268.0,9,0,2,0.0,8.942275608942275,None,266.0,1.0,1.0,34,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen2.5-Coder-32B-Instruct,260.0,9,0,2,0.0,8.675342008675342,None,258.0,1.0,1.0,35,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen2.5-Coder-7B-Instruct,209.0,9,0,2,0.0,6.97364030697364,None,207.0,1.0,1.0,36,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_1024,191.0,9,0,2,0.0,6.373039706373039,None,119.0,71.0,1.0,37,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_2048,153.0,9,0,3,0.0,5.105105105105105,None,60.0,71.0,22.0,38,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-4B-Non-Thinking,121.0,9,0,1,0.0,4.037370704037371,None,119.0,1.0,1.0,39,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_0,93.0,9,0,2,0.0,3.1031031031031033,None,21.0,71.0,1.0,40,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
seed-oss_512,93.0,9,0,2,0.0,3.1031031031031033,None,21.0,71.0,1.0,41,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
DeepSeek-R1-Distill-Llama-8B,73.0,9,0,1,0.0,2.435769102435769,None,1.0,71.0,1.0,42,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
DeepSeek-Coder-V2-Lite-Instruct,62.0,9,0,1,0.0,2.0687354020687354,None,60.0,1.0,1.0,43,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Codestral-22B-v0.1,42.0,9,0,1,0.0,1.4014014014014013,None,40.0,1.0,1.0,44,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-32B-Non-Thinking,3.0,9,0,0,0.0,0.10010010010010009,None,1.0,1.0,1.0,45,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Qwen3-14B-Non-Thinking,3.0,9,0,0,0.0,0.10010010010010009,None,1.0,1.0,1.0,46,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
Llama-3.1-8B-Instruct,3.0,9,0,0,0.0,0.10010010010010009,None,1.0,1.0,1.0,47,USACO,2023,combined,USACO-2023-US_Open_Contest-combined
