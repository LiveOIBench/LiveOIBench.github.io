Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gemini-2.5-pro,2,5,308.0,308.0,61.602,63.99199999999998,13.331999999999999,0,1,1,2,63.93099321898684,1
gpt-5,2,5,272.0,272.0,54.4,55.568,33.330000000000005,0,1,0,1,63.89110490626247,2
seed-oss_16384,2,5,218.0,218.0,43.602,42.584,13.331999999999999,0,0,1,1,43.51814918228959,3
gpt-o3-mini-high,2,5,214.0,214.0,42.798,39.12,13.331999999999999,0,0,1,1,43.51814918228959,4
gpt-oss-120b-high,2,5,136.0,136.0,27.198,29.168000000000006,13.331999999999999,0,0,1,1,30.67411248504188,5
gpt-oss-120b-low,2,5,129.0,129.0,25.8,25.195999999999998,13.331999999999999,0,0,1,1,29.75668129238133,6
gpt-oss-20b-medium,2,5,120.0,120.0,24.0,24.913999999999998,13.331999999999999,0,0,1,1,29.06860789788592,7
gpt-oss-120b-medium,2,5,120.0,120.0,24.0,23.233999999999998,13.331999999999999,0,0,1,1,29.06860789788592,8
DeepSeek-R1-Distill-Llama-70B,2,5,147.0,147.0,29.398000000000003,25.89,0.0,0,0,0,0,16.05504587155963,9
gemini-2.5-flash,2,5,144.0,144.0,28.8,42.932,0.0,0,0,0,0,25.91743119266055,10
gpt-oss-20b-high,2,5,137.0,137.0,27.398000000000003,29.124,13.331999999999999,0,0,0,0,15.371958516154766,11
gpt-4.1,2,5,131.0,131.0,26.198,30.885999999999996,0.0,0,0,0,0,17.431192660550458,12
Qwen3-32B,2,5,130.0,130.0,25.998,39.53,0.0,0,0,0,0,16.05504587155963,13
deepseek-chat,2,5,125.0,125.0,25.0,38.434000000000005,0.0,0,0,0,0,17.889908256880734,14
Qwen3-32B-Non-Thinking,2,5,113.0,113.0,22.6,25.509999999999998,0.0,0,0,0,0,17.431192660550458,15
seed-oss_-1,2,5,102.0,102.0,20.398,24.784,0.0,0,0,0,0,16.05504587155963,16
DeepSeek-R1-Distill-Qwen-14B,2,5,102.0,102.0,20.398,19.462000000000003,0.0,0,0,0,0,16.05504587155963,17
deepseek-reasoner,2,5,97.0,97.0,19.398,18.234,0.0,0,0,0,0,16.05504587155963,18
seed-oss_4096,2,5,97.0,97.0,19.398,18.234,0.0,0,0,0,0,16.05504587155963,19
seed-oss_0,2,5,63.0,63.0,12.6,12.618000000000002,0.0,0,0,0,0,8.715596330275229,20
DeepSeek-R1-Distill-Qwen-32B,2,5,60.0,60.0,11.998,18.19,0.0,0,0,0,0,7.339449541284404,21
seed-oss_8192,2,5,58.0,58.0,11.602,19.9,0.0,0,0,0,0,6.192660550458716,22
Qwen3-8B,2,5,50.0,50.0,9.998000000000001,17.668,0.0,0,0,0,0,4.587155963302752,23
seed-oss_512,2,5,44.0,44.0,8.802,7.074,0.0,0,0,0,0,5.73394495412844,24
Qwen3-14B,2,5,39.0,39.0,7.802,12.280000000000001,0.0,0,0,0,0,2.981651376146789,25
Qwen3-14B-Non-Thinking,2,5,36.0,36.0,7.198,16.956000000000003,0.0,0,0,0,0,4.587155963302752,26
DeepSeek-Coder-V2-Lite-Instruct,2,5,35.0,35.0,7.002,16.817999999999998,0.0,0,0,0,0,5.045871559633028,27
Qwen3-8B-Non-Thinking,2,5,31.0,31.0,6.198,13.62,0.0,0,0,0,0,4.587155963302752,28
Qwen3-30B-Non-Thinking,2,5,29.0,29.0,5.8,13.828,0.0,0,0,0,0,3.669724770642202,29
Codestral-22B-v0.1,2,5,26.0,26.0,5.202,13.374,0.0,0,0,0,0,4.128440366972477,30
Qwen2.5-Coder-32B-Instruct,2,5,26.0,26.0,5.202,13.128,0.0,0,0,0,0,4.128440366972477,31
Qwen3-30B,2,5,25.0,25.0,5.002,10.612000000000002,0.0,0,0,0,0,2.981651376146789,32
Qwen3-4B,2,5,25.0,25.0,5.002,10.612000000000002,0.0,0,0,0,0,2.981651376146789,33
gpt-oss-20b-low,2,5,24.0,24.0,4.8,11.202000000000002,0.0,0,0,0,0,3.669724770642202,34
Llama-4-Scout,2,5,20.0,20.0,4.0,14.565999999999999,0.0,0,0,0,0,2.981651376146789,35
Llama-3.1-8B-Instruct,2,5,20.0,20.0,4.0,6.279999999999999,0.0,0,0,0,0,2.981651376146789,36
QwQ-32B,2,5,20.0,20.0,4.002,8.004,0.0,0,0,0,0,2.981651376146789,37
seed-oss_2048,2,5,20.0,20.0,4.002,5.37,0.0,0,0,0,0,2.981651376146789,38
seed-oss_1024,2,5,20.0,20.0,4.002,8.022,0.0,0,0,0,0,2.981651376146789,39
Qwen2.5-72B,2,5,16.0,16.0,3.2019999999999995,11.362000000000002,0.0,0,0,0,0,2.7522935779816513,40
Mistral-Small-3.1-24B-2503,2,5,15.0,15.0,3.0,6.84,0.0,0,0,0,0,2.981651376146789,41
Qwen3-4B-Non-Thinking,2,5,11.0,11.0,2.202,13.476000000000003,0.0,0,0,0,0,2.7522935779816513,42
Qwen2.5-Coder-7B-Instruct,2,5,11.0,11.0,2.202,9.228,0.0,0,0,0,0,2.7522935779816513,43
Qwen2.5-Coder-14B-Instruct,2,5,11.0,11.0,2.202,9.852,0.0,0,0,0,0,2.7522935779816513,44
Llama-3.3-70B-Instruct,2,5,11.0,11.0,2.202,9.708,0.0,0,0,0,0,2.7522935779816513,45
Mistral-Large-Instruct-2411,2,5,5.0,5.0,1.0,2.3800000000000003,0.0,0,0,0,0,2.0642201834862384,46
DeepSeek-R1-Distill-Llama-8B,2,5,4.0,4.0,0.798,3.1979999999999995,0.0,0,0,0,0,2.0642201834862384,47
DeepSeek-R1-Distill-Qwen-7B,2,5,0.0,0.0,0.0,0.0,0.0,0,0,0,0,2.0642201834862384,48
