Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gpt-5,2,12,343.0,343.0,28.584999999999997,43.215,16.669999999999998,0,0,1,1,44.28776511994072,1
gemini-2.5-pro,2,12,294.0,294.0,24.5,46.295,0.0,0,0,1,1,36.77178845975734,2
gpt-oss-120b-high,2,12,295.0,295.0,24.58,40.755,16.669999999999998,0,0,0,0,34.51421691210521,3
seed-oss_-1,2,12,247.0,247.0,20.58,38.335,0.0,0,0,0,0,28.62137630823377,4
seed-oss_16384,2,12,222.0,222.0,18.5,35.97,0.0,0,0,0,0,24.666574048346764,5
seed-oss_8192,2,12,214.0,214.0,17.83,29.49,0.0,0,0,0,0,25.45614522552561,6
Qwen3-32B,2,12,192.0,192.0,16.0,30.509999999999998,0.0,0,0,0,0,21.732888765397796,7
gpt-o3-mini-high,2,12,179.0,179.0,14.920000000000002,24.315,0.0,0,0,0,0,20.3551912568306,8
gemini-2.5-flash,2,12,175.0,175.0,14.585,30.294999999999998,0.0,0,0,0,0,18.475039362785957,9
gpt-oss-120b-medium,2,12,151.0,151.0,12.579999999999998,28.109999999999996,0.0,0,0,0,0,14.920811336482355,10
Qwen3-30B,2,12,137.0,137.0,11.415,23.169999999999998,0.0,0,0,0,0,13.964527183476893,11
deepseek-reasoner,2,12,133.0,133.0,11.085,27.220000000000006,0.0,0,0,0,0,11.954709641567103,12
gpt-oss-20b-low,2,12,129.0,129.0,10.75,21.055,0.0,0,0,0,0,13.008243030471426,13
gpt-oss-20b-medium,2,12,129.0,129.0,10.75,24.115000000000002,0.0,0,0,0,0,12.075113457441883,14
gpt-oss-20b-high,2,12,128.0,128.0,10.665000000000001,24.370000000000005,0.0,0,0,0,0,11.792627581735669,15
Qwen3-14B,2,12,125.0,125.0,10.415000000000001,22.57,0.0,0,0,0,0,12.00101880151894,16
gpt-oss-120b-low,2,12,122.0,122.0,10.165000000000001,21.475,0.0,0,0,0,0,11.915346855608039,17
Qwen3-30B-Non-Thinking,2,12,111.0,111.0,9.25,18.740000000000002,0.0,0,0,0,0,12.491895897008428,18
Qwen3-8B,2,12,105.0,105.0,8.75,17.99,0.0,0,0,0,0,8.949245160692785,19
deepseek-chat,2,12,99.0,99.0,8.25,19.325,0.0,0,0,0,0,11.22997128832083,20
QwQ-32B,2,12,92.0,92.0,7.665,14.734999999999998,0.0,0,0,0,0,10.9521163286098,21
Qwen2.5-Coder-32B-Instruct,2,12,76.0,76.0,6.330000000000001,18.029999999999998,0.0,0,0,0,0,7.986014633694545,22
DeepSeek-R1-Distill-Llama-70B,2,12,75.0,75.0,6.25,20.97,0.0,0,0,0,0,5.533944614244698,23
gpt-4.1,2,12,74.0,74.0,6.165,15.659999999999998,0.0,0,0,0,0,7.407150134296564,24
Mistral-Large-Instruct-2411,2,12,66.0,66.0,5.5,14.280000000000001,0.0,0,0,0,0,7.712790589978698,25
Qwen3-14B-Non-Thinking,2,12,61.0,61.0,5.085,12.490000000000002,0.0,0,0,0,0,7.006575900713161,26
Qwen3-4B,2,12,50.0,50.0,4.165,12.485000000000001,0.0,0,0,0,0,3.7255719181254054,27
Qwen2.5-72B,2,12,47.0,47.0,3.9149999999999996,9.785,0.0,0,0,0,0,3.4523478744095586,28
Llama-3.3-70B-Instruct,2,12,44.0,44.0,3.6649999999999996,10.635,0.0,0,0,0,0,3.179123830693711,29
Qwen3-32B-Non-Thinking,2,12,44.0,44.0,3.67,10.975,0.0,0,0,0,0,4.600815041215153,30
Qwen3-8B-Non-Thinking,2,12,42.0,42.0,3.5,8.235000000000001,0.0,0,0,0,0,3.4523478744095586,31
DeepSeek-R1-Distill-Qwen-32B,2,12,40.0,40.0,3.3349999999999995,9.82,0.0,0,0,0,0,3.8946003519496157,32
Llama-4-Scout,2,12,34.0,34.0,2.83,10.32,0.0,0,0,0,0,2.905899786977864,33
seed-oss_4096,2,12,32.0,32.0,2.665,11.445,0.0,0,0,0,0,2.905899786977864,34
seed-oss_2048,2,12,26.0,26.0,2.165,8.43,0.0,0,0,0,0,3.3527831805131054,35
Qwen2.5-Coder-14B-Instruct,2,12,25.0,25.0,2.085,10.13,0.0,0,0,0,0,2.905899786977864,36
seed-oss_1024,2,12,25.0,25.0,2.08,11.785,0.0,0,0,0,0,2.632675743262017,37
DeepSeek-R1-Distill-Qwen-14B,2,12,25.0,25.0,2.08,6.99,0.0,0,0,0,0,2.632675743262017,38
Mistral-Small-3.1-24B-2503,2,12,22.0,22.0,1.835,6.890000000000001,0.0,0,0,0,0,2.769287765119941,39
DeepSeek-Coder-V2-Lite-Instruct,2,12,22.0,22.0,1.835,7.6,0.0,0,0,0,0,2.769287765119941,40
Qwen3-4B-Non-Thinking,2,12,22.0,22.0,1.835,6.245,0.0,0,0,0,0,2.769287765119941,41
seed-oss_512,2,12,22.0,22.0,1.835,4.944999999999999,0.0,0,0,0,0,3.216171158655182,42
Qwen2.5-Coder-7B-Instruct,2,12,12.0,12.0,1.0,5.5600000000000005,0.0,0,0,0,0,2.222839677688247,43
Llama-3.1-8B-Instruct,2,12,12.0,12.0,1.0,5.6899999999999995,0.0,0,0,0,0,2.222839677688247,44
seed-oss_0,2,12,11.0,11.0,0.915,3.7399999999999998,0.0,0,0,0,0,1.9496156339723998,45
DeepSeek-R1-Distill-Qwen-7B,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,1.6763915902565527,46
DeepSeek-R1-Distill-Llama-8B,2,12,0.0,0.0,0.0,1.755,0.0,0,0,0,0,1.6763915902565527,47
Codestral-22B-v0.1,2,12,0.0,0.0,0.0,1.6649999999999998,0.0,0,0,0,0,1.6763915902565527,48
