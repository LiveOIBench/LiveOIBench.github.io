Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gemini-2.5-pro,13,43,3333.0,3320.0,77.20930232558139,84.45046511627906,75.81395348837208,6,2,2,10,77.9970535446927,1
gpt-o3-mini-high,13,43,2934.0,2921.0,67.93023255813954,75.65069767441861,69.76744186046511,6,2,2,10,73.82889142688182,2
gemini-2.5-flash,13,43,2859.0,2846.0,66.18604651162791,77.80186046511629,65.58139534883722,5,3,2,10,70.91741162766147,3
Qwen3-32B,13,43,2109.0,2109.0,49.04651162790697,60.5986046511628,46.51162790697674,3,4,1,8,61.85796085857025,4
QwQ-32B,13,43,1997.0,1984.0,46.13953488372093,55.083023255813956,44.18604651162791,3,3,2,8,59.33786356238726,5
Qwen3-14B,13,43,1991.0,1978.0,46.0,57.21069767441859,44.651162790697676,2,4,2,8,59.09228167254162,6
deepseek-reasoner,13,43,1945.0,1932.0,44.93023255813954,55.55116279069768,42.7906976744186,1,5,2,8,59.7202980771175,7
gpt-4.1,13,43,1848.0,1835.0,42.674418604651166,54.119069767441864,40.46511627906976,0,6,2,8,58.70312972057354,8
deepseek-chat,13,43,1348.0,1335.0,31.046511627906977,42.513023255813955,33.95348837209302,0,1,7,8,47.67204384178803,9
Qwen3-30B,13,43,2026.0,2013.0,46.81395348837209,55.75767441860465,46.976744186046524,3,4,0,7,58.70927688062209,10
Qwen3-8B,13,43,1554.0,1541.0,35.83720930232558,45.918372093023265,33.95348837209302,0,3,4,7,51.491350371914756,11
DeepSeek-R1-Distill-Llama-70B,13,43,1106.0,1093.0,25.41860465116279,34.07976744186047,26.97674418604651,0,1,4,5,40.43386194145263,12
DeepSeek-R1-Distill-Qwen-32B,12,42,1049.0,1036.0,24.666666666666668,38.16095238095238,25.238095238095237,0,2,1,3,43.01873584651673,13
Qwen3-4B,13,43,862.0,849.0,19.74418604651163,30.301860465116278,20.0,0,1,2,3,35.198945809485565,14
Qwen3-32B-Non-Thinking,13,43,741.0,741.0,17.232558139534884,28.551162790697678,17.674418604651162,0,1,2,3,33.48038009750332,15
Qwen2.5-Coder-32B-Instruct,13,43,687.0,687.0,15.976744186046512,24.69348837209302,10.69767441860465,0,1,2,3,31.99425940222481,16
Qwen2.5-72B,13,43,732.0,732.0,17.023255813953487,29.231162790697667,17.674418604651162,0,1,1,2,30.313159536530936,17
Llama-3.3-70B-Instruct,13,43,485.0,485.0,11.279069767441861,21.758372093023254,13.023255813953488,0,1,1,2,25.811530688875145,18
DeepSeek-R1-Distill-Qwen-14B,13,43,703.0,690.0,16.046511627906977,23.022325581395346,17.674418604651162,0,1,0,1,28.415246042970413,19
Qwen2.5-Coder-14B-Instruct,13,43,559.0,559.0,13.0,21.202558139534887,10.69767441860465,0,1,0,1,24.007177622430522,20
Qwen3-30B-Non-Thinking,13,43,678.0,678.0,15.767441860465116,24.119534883720927,15.813953488372093,0,0,1,1,27.267618294447836,21
Mistral-Small-3.1-24B-2503,13,43,453.0,440.0,10.232558139534884,19.485581395348834,9.30232558139535,0,0,1,1,22.316522461592797,22
Qwen3-4B-Non-Thinking,13,43,329.0,329.0,7.651162790697675,15.876744186046512,4.651162790697675,0,0,1,1,17.39609808029365,23
Mistral-Large-Instruct-2411,13,43,505.0,505.0,11.744186046511627,23.653953488372096,11.162790697674419,0,0,0,0,19.431710416201664,24
Qwen3-8B-Non-Thinking,13,43,500.0,487.0,11.325581395348838,21.21697674418605,8.837209302325581,0,0,0,0,19.377916253615687,25
DeepSeek-Coder-V2-Lite-Instruct,13,43,381.0,368.0,8.55813953488372,14.555116279069766,2.3255813953488373,0,0,0,0,15.650055006603388,26
Qwen3-14B-Non-Thinking,13,43,356.0,356.0,8.279069767441861,16.30674418604651,9.41860465116279,0,0,0,0,16.872789319156112,27
Codestral-22B-v0.1,13,43,345.0,345.0,8.023255813953488,14.804651162790694,6.511627906976744,0,0,0,0,17.695512971160458,28
Qwen2.5-Coder-7B-Instruct,13,43,230.0,230.0,5.348837209302325,10.180232558139533,4.186046511627907,0,0,0,0,13.702128149709004,29
Llama-3.1-8B-Instruct,12,42,128.0,128.0,3.0476190476190474,6.9278571428571425,2.380952380952381,0,0,0,0,9.448900679482067,30
DeepSeek-R1-Distill-Llama-8B,12,42,35.0,22.0,0.5238095238095238,1.2035714285714287,0.0,0,0,0,0,7.475800244185524,31
DeepSeek-R1-Distill-Qwen-7B,4,15,0.0,0.0,0.0,0.0,0.0,0,0,0,0,8.895915145915145,32
