Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gpt-5,2,13,900.0,900.0,69.23230769230769,54.807692307692314,54.807692307692314,1,1,0,2,88.03191489361703,1
gemini-2.5-pro,2,13,800.0,800.0,61.54230769230769,57.29461538461539,44.230769230769226,1,1,0,2,82.69639934533552,2
gpt-oss-120b-high,2,13,736.0,736.0,56.61846153846154,47.74153846153846,43.269230769230774,1,1,0,2,82.64729950900164,3
gpt-o3-mini-high,2,13,706.0,706.0,54.309230769230766,50.92,37.5,0,1,1,2,74.31942171303874,4
gpt-oss-120b-medium,2,13,548.0,548.0,42.153076923076924,38.35153846153846,30.76923076923077,0,1,0,1,54.847244953627936,5
gemini-2.5-flash,2,13,537.0,537.0,41.30692307692308,43.010000000000005,25.961538461538463,0,1,0,1,57.62411347517731,6
deepseek-reasoner,2,13,505.0,505.0,38.84384615384616,40.990769230769224,25.961538461538463,0,1,0,1,54.784506273867976,7
gpt-oss-20b-high,2,13,500.0,500.0,38.46153846153846,38.65384615384615,38.65384615384615,0,1,0,1,55.46781232951446,8
Qwen3-30B,2,13,387.0,387.0,29.76923076923077,36.65538461538462,20.192307692307693,0,1,0,1,42.220403709765414,9
QwQ-32B,2,13,333.0,333.0,25.616153846153846,31.18846153846154,13.461538461538462,0,1,0,1,35.83742498636116,10
gpt-oss-20b-medium,2,13,636.0,536.0,41.230000000000004,43.313076923076935,36.53846153846153,0,0,1,1,53.30878341516639,11
seed-oss_-1,2,13,461.0,461.0,35.45923076923077,35.61153846153846,25.0,0,0,1,1,46.05428259683579,12
deepseek-chat,2,13,317.0,317.0,24.382307692307695,31.604615384615386,13.461538461538462,0,0,1,1,30.669667212220403,13
Qwen3-32B,2,13,315.0,315.0,24.23153846153846,36.41076923076923,13.461538461538462,0,0,1,1,30.669667212220403,14
gpt-4.1,2,13,297.0,297.0,22.847692307692306,31.66923076923076,13.461538461538462,0,0,1,1,30.53737043098745,15
DeepSeek-R1-Distill-Llama-70B,2,13,288.0,288.0,22.154615384615383,33.88461538461539,13.461538461538462,0,0,1,1,27.849154391707582,16
gpt-oss-20b-low,2,13,472.0,372.0,28.616153846153846,33.46923076923077,25.0,0,0,0,0,35.10365521003819,17
seed-oss_8192,2,13,324.0,324.0,24.923846153846153,26.49923076923077,19.230769230769234,0,0,0,0,29.206219312602293,18
gpt-oss-120b-low,2,13,295.0,295.0,22.69,29.218461538461536,13.461538461538462,0,0,0,0,26.898527004909983,19
Qwen3-14B,2,13,257.0,257.0,19.76846153846154,29.65076923076923,13.461538461538462,0,0,0,0,22.79596290234588,20
seed-oss_4096,2,13,256.0,256.0,19.69,20.615384615384613,13.461538461538462,0,0,0,0,22.79596290234588,21
seed-oss_16384,2,13,235.0,235.0,18.07846153846154,19.490769230769228,11.538461538461538,0,0,0,0,21.576650300054556,22
DeepSeek-R1-Distill-Qwen-32B,2,13,223.0,223.0,17.156153846153845,27.561538461538465,6.730769230769231,0,0,0,0,18.816148390616476,23
DeepSeek-R1-Distill-Qwen-14B,2,13,180.0,180.0,13.842307692307692,20.339999999999996,0.0,0,0,0,0,16.47026732133115,24
seed-oss_2048,2,13,153.0,153.0,11.76769230769231,17.08846153846154,6.730769230769231,0,0,0,0,13.544735406437534,25
Qwen3-14B-Non-Thinking,2,13,143.0,143.0,10.997692307692308,15.727692307692307,6.730769230769231,0,0,0,0,11.407528641571195,26
Qwen3-8B,2,13,132.0,132.0,10.154615384615385,19.33,6.730769230769231,0,0,0,0,8.72885979268958,27
Qwen3-4B,2,13,132.0,132.0,10.154615384615385,19.426923076923078,6.730769230769231,0,0,0,0,8.72885979268958,28
Llama-3.1-8B-Instruct,2,13,130.0,30.0,2.31,10.933076923076923,5.769230769230769,0,0,0,0,1.842607746863066,29
Codestral-22B-v0.1,2,13,130.0,130.0,9.99923076923077,13.813076923076922,6.730769230769231,0,0,0,0,11.94899072558647,30
seed-oss_0,2,13,116.0,116.0,8.926923076923076,14.511538461538459,6.730769230769231,0,0,0,0,7.9596290234588105,31
seed-oss_1024,2,13,114.0,114.0,8.77,11.693076923076921,6.730769230769231,0,0,0,0,7.9596290234588105,32
seed-oss_512,2,13,96.0,96.0,7.384615384615385,11.554615384615383,0.0,0,0,0,0,7.42771412984179,33
Llama-3.3-70B-Instruct,2,13,95.0,95.0,7.305384615384615,15.22923076923077,0.0,0,0,0,0,4.178941625750136,34
Qwen2.5-72B,2,13,91.0,91.0,6.997692307692308,14.416923076923077,0.0,0,0,0,0,4.919530823786143,35
Qwen2.5-Coder-32B-Instruct,2,13,89.0,89.0,6.845384615384616,16.39923076923077,0.0,0,0,0,0,5.005455537370431,36
Qwen3-30B-Non-Thinking,2,13,72.0,72.0,5.536923076923076,18.35,0.0,0,0,0,0,2.877795962902346,37
Qwen2.5-Coder-14B-Instruct,2,13,69.0,69.0,5.308461538461539,13.704615384615385,0.0,0,0,0,0,4.236224768139662,38
DeepSeek-Coder-V2-Lite-Instruct,2,13,55.0,55.0,4.231538461538462,11.093846153846153,0.0,0,0,0,0,2.640480087288598,39
Mistral-Small-3.1-24B-2503,2,13,53.0,53.0,4.076153846153846,10.067692307692308,0.0,0,0,0,0,4.236224768139662,40
Qwen3-32B-Non-Thinking,2,13,50.0,50.0,3.8446153846153845,8.620769230769234,0.0,0,0,0,0,4.236224768139662,41
Llama-4-Scout,2,13,47.0,47.0,3.614615384615384,12.899230769230769,0.0,0,0,0,0,2.0990180032733226,42
Mistral-Large-Instruct-2411,2,13,41.0,41.0,3.1546153846153846,13.51,0.0,0,0,0,0,1.842607746863066,43
Qwen3-8B-Non-Thinking,2,13,39.0,39.0,2.996153846153846,13.947692307692309,0.0,0,0,0,0,2.0990180032733226,44
Qwen3-4B-Non-Thinking,2,13,20.0,20.0,1.536923076923077,10.896153846153847,0.0,0,0,0,0,1.8330605564648117,45
DeepSeek-R1-Distill-Llama-8B,2,13,14.0,14.0,1.0753846153846154,2.4323076923076923,0.0,0,0,0,0,1.5766503000545553,46
DeepSeek-R1-Distill-Qwen-7B,2,13,0.0,0.0,0.0,0.0,0.0,0,0,0,0,1.5766503000545553,47
Qwen2.5-Coder-7B-Instruct,2,13,0.0,0.0,0.0,5.654615384615385,0.0,0,0,0,0,1.5766503000545553,48
