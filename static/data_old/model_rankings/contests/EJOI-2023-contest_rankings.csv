Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gpt-o3-mini-high,227.0,6,227.0,40.96,16.67,Silver,21,78.26086956521739,1,37.83
gemini-2.5-pro,203.0,6,203.0,44.19,16.67,Bronze,27,71.73913043478261,2,33.83
gemini-2.5-flash,162.0,6,162.0,30.59,0.0,Bronze,40,57.608695652173914,3,27.0
QwQ-32B,118.0,6,118.0,23.96,0.0,Bronze,58,38.04347826086956,4,19.67
deepseek-reasoner,107.0,6,107.0,22.75,0.0,Bronze,60,35.869565217391305,5,17.83
Qwen3-32B,87.0,6,87.0,22.57,0.0,Bronze,67,28.26086956521739,6,14.5
Qwen3-14B,79.0,6,79.0,14.88,0.0,None,72,22.82608695652174,7,13.17
Qwen3-4B,68.0,6,68.0,13.47,0.0,None,75,19.565217391304348,8,11.33
Qwen3-30B,68.0,6,68.0,16.21,0.0,None,75,19.565217391304348,9,11.33
Qwen3-8B,59.0,6,59.0,14.03,0.0,None,78,16.304347826086957,10,9.83
Llama-3.3-70B-Instruct,51.0,6,51.0,16.33,0.0,None,78,16.304347826086957,11,8.5
DeepSeek-R1-Distill-Qwen-32B,50.0,6,50.0,11.01,0.0,None,78,16.304347826086957,12,8.33
deepseek-chat,43.0,6,43.0,11.29,0.0,None,79,15.217391304347826,13,7.17
Qwen3-32B-Non-Thinking,40.0,6,40.0,11.07,0.0,None,79,15.217391304347826,14,6.67
Qwen2.5-Coder-32B-Instruct,25.0,6,25.0,7.24,0.0,None,82,11.956521739130435,15,4.17
DeepSeek-R1-Distill-Llama-70B,16.0,6,16.0,6.22,0.0,None,86,7.608695652173913,16,2.67
DeepSeek-R1-Distill-Qwen-14B,16.0,6,16.0,5.91,0.0,None,86,7.608695652173913,17,2.67
gpt-4.1,14.0,6,14.0,9.71,0.0,None,86,7.608695652173913,18,2.33
Qwen3-4B-Non-Thinking,5.0,6,5.0,2.49,0.0,None,86,7.608695652173913,19,0.83
Mistral-Small-3.1-24B-2503,5.0,6,5.0,2.74,0.0,None,86,7.608695652173913,20,0.83
Qwen2.5-72B,5.0,6,5.0,6.34,0.0,None,86,7.608695652173913,21,0.83
Mistral-Large-Instruct-2411,5.0,6,5.0,4.38,0.0,None,86,7.608695652173913,22,0.83
Qwen3-14B-Non-Thinking,5.0,6,5.0,2.76,0.0,None,86,7.608695652173913,23,0.83
Qwen3-30B-Non-Thinking,5.0,6,5.0,5.74,0.0,None,86,7.608695652173913,24,0.83
Qwen2.5-Coder-14B-Instruct,5.0,6,5.0,3.86,0.0,None,86,7.608695652173913,25,0.83
DeepSeek-R1-Distill-Qwen-7B,0.0,6,0.0,0.0,0.0,None,91,2.1739130434782608,26,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,6,0.0,0.0,0.0,None,91,2.1739130434782608,27,0.0
Llama-3.1-8B-Instruct,0.0,6,0.0,0.27,0.0,None,91,2.1739130434782608,28,0.0
Codestral-22B-v0.1,0.0,6,0.0,0.27,0.0,None,91,2.1739130434782608,29,0.0
Qwen3-8B-Non-Thinking,0.0,6,0.0,0.4,0.0,None,91,2.1739130434782608,30,0.0
Qwen2.5-Coder-7B-Instruct,0.0,6,0.0,0.55,0.0,None,91,2.1739130434782608,31,0.0
DeepSeek-Coder-V2-Lite-Instruct,0.0,6,0.0,0.77,0.0,None,91,2.1739130434782608,32,0.0
