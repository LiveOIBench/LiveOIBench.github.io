Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gemini-2.5-pro,351.0,11,351.0,53.52,16.67,Bronze,231,59.79020979020979,1,31.91
gpt-o3-mini-high,278.0,11,278.0,49.9,16.67,Bronze,261,54.54545454545455,2,25.27
gemini-2.5-flash,217.0,11,217.0,48.83,8.33,None,290,49.47552447552447,3,19.73
Qwen3-32B,196.0,11,196.0,42.65,8.33,None,353,38.46153846153846,4,17.82
Qwen3-14B,172.0,11,172.0,36.21,8.33,None,357,37.76223776223776,5,15.64
Qwen3-8B,147.0,11,147.0,31.58,8.33,None,379,33.91608391608391,6,13.36
deepseek-reasoner,129.0,11,129.0,41.34,0.0,None,385,32.86713286713287,7,11.73
Qwen3-32B-Non-Thinking,109.0,11,109.0,19.8,8.33,None,406,29.195804195804197,8,9.91
gpt-4.1,91.0,11,91.0,40.61,0.0,None,452,21.153846153846153,9,8.27
QwQ-32B,68.0,11,68.0,29.04,0.0,None,477,16.783216783216783,10,6.18
Qwen3-30B,62.0,11,62.0,36.57,0.0,None,480,16.25874125874126,11,5.64
deepseek-chat,53.0,11,53.0,27.33,0.0,None,495,13.636363636363637,12,4.82
Qwen3-4B,50.0,11,50.0,24.17,0.0,None,495,13.636363636363637,13,4.55
DeepSeek-R1-Distill-Llama-70B,48.0,11,48.0,18.52,0.0,None,497,13.286713286713287,14,4.36
Qwen2.5-Coder-32B-Instruct,46.0,11,46.0,21.77,0.0,None,497,13.286713286713287,15,4.18
DeepSeek-R1-Distill-Qwen-32B,28.0,11,28.0,22.12,0.0,None,519,9.44055944055944,16,2.55
Mistral-Large-Instruct-2411,22.0,11,22.0,16.93,0.0,None,533,6.993006993006993,17,2.0
Qwen2.5-Coder-14B-Instruct,21.0,11,21.0,17.96,0.0,None,537,6.293706293706293,18,1.91
Qwen2.5-72B,16.0,11,16.0,12.51,0.0,None,542,5.419580419580419,19,1.45
Qwen3-30B-Non-Thinking,15.0,11,15.0,9.98,0.0,None,548,4.370629370629371,20,1.36
Codestral-22B-v0.1,8.0,11,8.0,9.15,0.0,None,557,2.797202797202797,21,0.73
DeepSeek-R1-Distill-Qwen-14B,7.0,11,7.0,7.08,0.0,None,557,2.797202797202797,22,0.64
Llama-3.3-70B-Instruct,6.0,11,6.0,11.53,0.0,None,559,2.4475524475524475,23,0.55
Qwen3-14B-Non-Thinking,5.0,11,5.0,9.29,0.0,None,565,1.3986013986013985,24,0.45
Qwen3-4B-Non-Thinking,5.0,11,5.0,7.23,0.0,None,565,1.3986013986013985,25,0.45
DeepSeek-Coder-V2-Lite-Instruct,5.0,11,5.0,9.52,0.0,None,565,1.3986013986013985,26,0.45
Qwen3-8B-Non-Thinking,5.0,11,5.0,9.04,0.0,None,565,1.3986013986013985,27,0.45
DeepSeek-R1-Distill-Qwen-7B,0.0,11,0.0,0.0,0.0,None,573,0.0,28,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,11,0.0,0.0,0.0,None,573,0.0,29,0.0
Llama-3.1-8B-Instruct,0.0,11,0.0,2.08,0.0,None,573,0.0,30,0.0
Qwen2.5-Coder-7B-Instruct,0.0,11,0.0,7.41,0.0,None,573,0.0,31,0.0
Mistral-Small-3.1-24B-2503,0.0,11,0.0,5.77,0.0,None,573,0.0,32,0.0
