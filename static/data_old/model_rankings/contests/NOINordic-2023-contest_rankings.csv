Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
deepseek-reasoner,300.0,3,300.0,100.0,100.0,Gold,1,100.0,1,100.0
gpt-o3-mini-high,264.0,3,264.0,93.9,66.67,Gold,2,98.50746268656717,2,88.0
gemini-2.5-pro,241.0,3,241.0,85.99,66.67,Gold,5,94.02985074626865,3,80.33
Qwen3-32B,229.0,3,229.0,91.17,66.67,Gold,5,94.02985074626865,4,76.33
gpt-4.1,229.0,3,229.0,91.17,66.67,Gold,5,94.02985074626865,5,76.33
gemini-2.5-flash,222.0,3,222.0,88.58,66.67,Silver,9,88.05970149253731,6,74.0
Qwen3-14B,217.0,3,217.0,80.69,66.67,Silver,10,86.56716417910448,7,72.33
deepseek-chat,212.0,3,212.0,86.44,66.67,Silver,10,86.56716417910448,8,70.67
Qwen3-30B,200.0,3,200.0,80.78,66.67,Silver,14,80.59701492537313,9,66.67
QwQ-32B,191.0,3,191.0,86.15,33.33,Bronze,17,76.11940298507463,10,63.67
DeepSeek-R1-Distill-Llama-70B,179.0,3,179.0,72.93,33.33,Bronze,17,76.11940298507463,11,59.67
Qwen3-8B,179.0,3,179.0,71.48,33.33,Bronze,17,76.11940298507463,12,59.67
DeepSeek-R1-Distill-Qwen-32B,143.0,3,143.0,78.15,0.0,Bronze,21,70.14925373134328,13,47.67
Llama-3.3-70B-Instruct,109.0,3,109.0,74.28,0.0,Bronze,23,67.16417910447761,14,36.33
Mistral-Small-3.1-24B-2503,107.0,3,107.0,62.85,33.33,Bronze,24,65.67164179104478,15,35.67
Qwen2.5-72B,107.0,3,107.0,63.09,33.33,Bronze,24,65.67164179104478,16,35.67
Qwen3-32B-Non-Thinking,103.0,3,103.0,58.25,0.0,Bronze,25,64.17910447761194,17,34.33
Qwen3-4B-Non-Thinking,100.0,3,100.0,35.48,33.33,Bronze,25,64.17910447761194,18,33.33
DeepSeek-R1-Distill-Qwen-14B,91.0,3,91.0,55.85,0.0,Bronze,28,59.701492537313435,19,30.33
Mistral-Large-Instruct-2411,59.0,3,59.0,55.09,0.0,Bronze,32,53.73134328358209,20,19.67
Qwen3-14B-Non-Thinking,59.0,3,59.0,40.74,0.0,Bronze,32,53.73134328358209,21,19.67
Qwen2.5-Coder-14B-Instruct,59.0,3,59.0,42.1,0.0,Bronze,32,53.73134328358209,22,19.67
Qwen3-8B-Non-Thinking,44.0,3,44.0,28.31,0.0,None,38,44.776119402985074,23,14.67
Qwen3-4B,42.0,3,42.0,47.94,0.0,None,39,43.28358208955224,24,14.0
DeepSeek-Coder-V2-Lite-Instruct,37.0,3,37.0,14.71,0.0,None,40,41.791044776119406,25,12.33
Codestral-22B-v0.1,29.0,3,29.0,39.46,0.0,None,41,40.298507462686565,26,9.67
Llama-3.1-8B-Instruct,24.0,3,24.0,21.74,0.0,None,41,40.298507462686565,27,8.0
Qwen2.5-Coder-32B-Instruct,7.0,3,7.0,30.84,0.0,None,44,35.82089552238806,28,2.33
Qwen3-30B-Non-Thinking,0.0,3,0.0,0.0,0.0,None,57,16.417910447761194,29,0.0
DeepSeek-R1-Distill-Qwen-7B,0.0,3,0.0,0.0,0.0,None,57,16.417910447761194,30,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,3,0.0,1.08,0.0,None,57,16.417910447761194,31,0.0
