Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gemini-2.5-pro,657.0,8,657.0,79.31,66.67,Gold,59,95.03849443969204,1,82.12
gpt-o3-mini-high,569.0,8,569.0,74.66,44.44,Silver,200,82.97690333618478,2,71.12
gemini-2.5-flash,538.0,8,538.0,76.8,33.33,Silver,271,76.90333618477331,3,67.25
Qwen3-32B,460.0,8,460.0,69.16,22.22,Bronze,433,63.045337895637296,4,57.5
deepseek-reasoner,423.0,8,423.0,63.24,22.22,Bronze,469,59.96578272027374,5,52.88
Qwen3-30B,397.0,8,397.0,67.57,22.22,Bronze,501,57.2284003421728,6,49.62
Qwen3-8B,397.0,8,397.0,66.62,22.22,Bronze,501,57.2284003421728,7,49.62
Qwen3-14B,379.0,8,379.0,62.9,22.22,Bronze,508,56.629597946963216,8,47.38
DeepSeek-R1-Distill-Qwen-32B,314.0,8,314.0,53.81,11.11,Bronze,542,53.72112917023097,9,39.25
QwQ-32B,313.0,8,313.0,54.62,22.22,Bronze,542,53.72112917023097,10,39.12
DeepSeek-R1-Distill-Llama-70B,297.0,8,297.0,55.01,11.11,Bronze,559,52.26689478186484,11,37.12
Qwen3-4B,263.0,8,263.0,58.11,11.11,Bronze,574,50.98374679213003,12,32.88
deepseek-chat,253.0,8,253.0,57.49,11.11,Bronze,579,50.556030795551756,13,31.62
DeepSeek-R1-Distill-Qwen-14B,240.0,8,240.0,33.22,22.22,None,588,49.786142001710864,14,30.0
Qwen2.5-Coder-32B-Instruct,220.0,8,220.0,38.67,11.11,None,594,49.272882805816934,15,27.5
gpt-4.1,200.0,8,200.0,42.22,11.11,None,641,45.25235243798118,16,25.0
Llama-3.3-70B-Instruct,190.0,8,190.0,36.29,11.11,None,644,44.99572284003422,17,23.75
Qwen3-32B-Non-Thinking,189.0,8,189.0,33.36,11.11,None,644,44.99572284003422,18,23.62
Qwen3-30B-Non-Thinking,168.0,8,168.0,30.5,11.11,None,652,44.31137724550898,19,21.0
Qwen3-14B-Non-Thinking,165.0,8,165.0,28.83,11.11,None,652,44.31137724550898,20,20.62
Qwen2.5-Coder-14B-Instruct,155.0,8,155.0,27.01,11.11,None,657,43.88366124893071,21,19.38
Mistral-Small-3.1-24B-2503,135.0,8,135.0,30.51,11.11,None,669,42.857142857142854,22,16.88
Qwen3-4B-Non-Thinking,112.0,8,112.0,26.28,0.0,None,705,39.7775876817793,23,14.0
Qwen2.5-72B,102.0,8,102.0,21.92,0.0,None,719,38.57998289136014,24,12.75
Codestral-22B-v0.1,100.0,8,100.0,12.41,11.11,None,785,32.93413173652694,25,12.5
DeepSeek-Coder-V2-Lite-Instruct,100.0,8,100.0,19.53,11.11,None,785,32.93413173652694,26,12.5
Mistral-Large-Instruct-2411,60.0,8,60.0,25.5,0.0,None,830,29.0846877673225,27,7.5
DeepSeek-R1-Distill-Llama-8B,30.0,8,30.0,4.89,0.0,None,867,25.919589392643285,28,3.75
Qwen3-8B-Non-Thinking,14.0,8,14.0,12.65,0.0,None,914,21.899059024807528,29,1.75
Llama-3.1-8B-Instruct,0.0,8,0.0,0.0,0.0,None,963,17.70744225834046,30,0.0
Qwen2.5-Coder-7B-Instruct,0.0,8,0.0,2.0,0.0,None,963,17.70744225834046,31,0.0
