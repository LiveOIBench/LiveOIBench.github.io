Model,Total Score,Included Tasks,Solved Tasks,Partial Tasks,Pass Rate (%),Relative Score (%),Medal,Bronze Score,Silver Score,Gold Score,Rank,Competition,Year,Round,Contest_Key
gpt-o3-mini-high,2134.0,9,6,2,66.66666666666666,71.20453787120454,Silver,1000.0,750.0,384.0,1,USACO,2025,combined,USACO-2025-January_Contest-combined
gemini-2.5-pro,2124.0,9,6,2,66.66666666666666,70.87087087087087,Silver,1000.0,723.0,401.0,2,USACO,2025,combined,USACO-2025-January_Contest-combined
gemini-2.5-flash,1901.0,9,5,3,55.55555555555556,63.4300967634301,Bronze,1000.0,667.0,234.0,3,USACO,2025,combined,USACO-2025-January_Contest-combined
deepseek-reasoner,1534.0,9,4,3,44.44444444444444,51.184517851184516,Bronze,700.0,667.0,167.0,4,USACO,2025,combined,USACO-2025-January_Contest-combined
QwQ-32B,1401.0,9,4,2,44.44444444444444,46.74674674674675,Bronze,700.0,667.0,34.0,5,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-14B,1168.0,9,3,3,33.33333333333333,38.9723056389723,Bronze,700.0,434.0,34.0,6,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-32B,1134.0,9,3,4,33.33333333333333,37.83783783783784,Bronze,700.0,378.0,56.0,7,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-8B,1002.0,9,3,0,33.33333333333333,33.433433433433436,None,334.0,667.0,1.0,8,USACO,2025,combined,USACO-2025-January_Contest-combined
gpt-4.1,785.0,9,1,5,11.11111111111111,26.19285952619286,None,334.0,367.0,84.0,9,USACO,2025,combined,USACO-2025-January_Contest-combined
DeepSeek-R1-Distill-Qwen-32B,724.0,9,1,4,11.11111111111111,24.15749082415749,None,667.0,23.0,34.0,10,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-30B,524.0,9,1,4,11.11111111111111,17.48415081748415,None,367.0,123.0,34.0,11,USACO,2025,combined,USACO-2025-January_Contest-combined
DeepSeek-R1-Distill-Llama-70B,447.0,9,1,2,11.11111111111111,14.914914914914915,None,334.0,112.0,1.0,12,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-4B,337.0,9,0,2,0.0,11.244577911244578,None,268.0,68.0,1.0,13,USACO,2025,combined,USACO-2025-January_Contest-combined
DeepSeek-R1-Distill-Qwen-14B,336.0,9,1,0,11.11111111111111,11.21121121121121,None,334.0,1.0,1.0,14,USACO,2025,combined,USACO-2025-January_Contest-combined
Llama-3.3-70B-Instruct,275.0,9,0,5,0.0,9.175842509175842,None,234.0,40.0,1.0,15,USACO,2025,combined,USACO-2025-January_Contest-combined
deepseek-chat,269.0,9,0,4,0.0,8.975642308975642,None,134.0,101.0,34.0,16,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen2.5-72B,258.0,9,0,4,0.0,8.608608608608609,None,234.0,23.0,1.0,17,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen2.5-Coder-14B-Instruct,253.0,9,0,4,0.0,8.441775108441774,None,234.0,18.0,1.0,18,USACO,2025,combined,USACO-2025-January_Contest-combined
Mistral-Small-3.1-24B-2503,236.0,9,0,3,0.0,7.874541207874541,None,234.0,1.0,1.0,19,USACO,2025,combined,USACO-2025-January_Contest-combined
DeepSeek-Coder-V2-Lite-Instruct,220.0,9,0,3,0.0,7.340674007340674,None,201.0,18.0,1.0,20,USACO,2025,combined,USACO-2025-January_Contest-combined
Mistral-Large-Instruct-2411,197.0,9,0,4,0.0,6.5732399065732405,None,134.0,62.0,1.0,21,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-14B-Non-Thinking,180.0,9,0,3,0.0,6.006006006006006,None,134.0,45.0,1.0,22,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-30B-Non-Thinking,169.0,9,0,3,0.0,5.638972305638972,None,134.0,34.0,1.0,23,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-4B-Non-Thinking,169.0,9,0,3,0.0,5.638972305638972,None,134.0,34.0,1.0,24,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen2.5-Coder-7B-Instruct,153.0,9,0,3,0.0,5.105105105105105,None,134.0,18.0,1.0,25,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-8B-Non-Thinking,136.0,9,0,2,0.0,4.537871204537871,None,134.0,1.0,1.0,26,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen2.5-Coder-32B-Instruct,136.0,9,0,2,0.0,4.537871204537871,None,134.0,1.0,1.0,27,USACO,2025,combined,USACO-2025-January_Contest-combined
Codestral-22B-v0.1,120.0,9,0,2,0.0,4.004004004004004,None,101.0,18.0,1.0,28,USACO,2025,combined,USACO-2025-January_Contest-combined
Qwen3-32B-Non-Thinking,103.0,9,0,1,0.0,3.4367701034367704,None,101.0,1.0,1.0,29,USACO,2025,combined,USACO-2025-January_Contest-combined
DeepSeek-R1-Distill-Llama-8B,3.0,9,0,0,0.0,0.10010010010010009,None,1.0,1.0,1.0,30,USACO,2025,combined,USACO-2025-January_Contest-combined
Llama-3.1-8B-Instruct,3.0,9,0,0,0.0,0.10010010010010009,None,1.0,1.0,1.0,31,USACO,2025,combined,USACO-2025-January_Contest-combined
