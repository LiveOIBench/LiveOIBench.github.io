Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gemini-2.5-pro,134.0,6,134.0,50.02,0.0,None,286,22.131147540983605,1,22.33
deepseek-reasoner,120.0,6,120.0,44.63,0.0,None,295,19.672131147540984,2,20.0
gemini-2.5-flash,112.0,6,112.0,39.91,0.0,None,300,18.306010928961747,3,18.67
Qwen3-32B,105.0,6,105.0,34.01,0.0,None,302,17.759562841530055,4,17.5
Qwen3-30B,105.0,6,105.0,33.44,0.0,None,302,17.759562841530055,5,17.5
Qwen3-14B,102.0,6,102.0,32.42,0.0,None,305,16.939890710382514,6,17.0
Qwen3-8B,92.0,6,92.0,28.7,0.0,None,317,13.66120218579235,7,15.33
gpt-o3-mini-high,67.0,6,67.0,19.0,0.0,None,340,7.377049180327869,8,11.17
DeepSeek-R1-Distill-Llama-70B,62.0,6,62.0,31.53,0.0,None,342,6.830601092896175,9,10.33
Qwen3-4B,45.0,6,45.0,20.89,0.0,None,348,5.191256830601093,10,7.5
gpt-4.1,42.0,6,42.0,20.06,0.0,None,350,4.644808743169399,11,7.0
Qwen2.5-72B,42.0,6,42.0,17.21,0.0,None,350,4.644808743169399,12,7.0
Qwen3-8B-Non-Thinking,42.0,6,42.0,15.82,0.0,None,350,4.644808743169399,13,7.0
Qwen3-30B-Non-Thinking,42.0,6,42.0,15.82,0.0,None,350,4.644808743169399,14,7.0
Llama-3.3-70B-Instruct,39.0,6,39.0,15.97,0.0,None,352,4.098360655737705,15,6.5
deepseek-chat,37.0,6,37.0,15.98,0.0,None,352,4.098360655737705,16,6.17
QwQ-32B,33.0,6,33.0,14.78,0.0,None,353,3.8251366120218577,17,5.5
Qwen2.5-Coder-32B-Instruct,32.0,6,32.0,20.23,0.0,None,353,3.8251366120218577,18,5.33
DeepSeek-R1-Distill-Qwen-32B,27.0,6,27.0,11.22,0.0,None,354,3.551912568306011,19,4.5
Qwen3-32B-Non-Thinking,25.0,6,25.0,12.81,0.0,None,354,3.551912568306011,20,4.17
Qwen2.5-Coder-14B-Instruct,25.0,6,25.0,14.74,0.0,None,354,3.551912568306011,21,4.17
Mistral-Small-3.1-24B-2503,22.0,6,22.0,12.02,0.0,None,355,3.278688524590164,22,3.67
DeepSeek-Coder-V2-Lite-Instruct,22.0,6,22.0,12.16,0.0,None,355,3.278688524590164,23,3.67
Qwen3-4B-Non-Thinking,22.0,6,22.0,11.94,0.0,None,355,3.278688524590164,24,3.67
Qwen3-14B-Non-Thinking,22.0,6,22.0,12.59,0.0,None,355,3.278688524590164,25,3.67
Mistral-Large-Instruct-2411,22.0,6,22.0,14.27,0.0,None,355,3.278688524590164,26,3.67
DeepSeek-R1-Distill-Qwen-14B,20.0,6,20.0,9.26,0.0,None,356,3.0054644808743167,27,3.33
Qwen2.5-Coder-7B-Instruct,12.0,6,12.0,10.97,0.0,None,359,2.185792349726776,28,2.0
Llama-3.1-8B-Instruct,12.0,6,12.0,9.68,0.0,None,359,2.185792349726776,29,2.0
DeepSeek-R1-Distill-Qwen-7B,0.0,6,0.0,0.0,0.0,None,363,1.092896174863388,30,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,6,0.0,1.36,0.0,None,363,1.092896174863388,31,0.0
Codestral-22B-v0.1,0.0,6,0.0,2.67,0.0,None,363,1.092896174863388,32,0.0
